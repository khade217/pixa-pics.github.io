/*! For license information please see chunk_62.min.js.LICENSE.txt */
(window.webpackJsonp=window.webpackJsonp||[]).push([[62],{1208:function(e,t,s){"use strict";function n(e,t,s=""){if("number"!=typeof e&&"number"!=typeof t){a.Si.assert(e.length===t.length,(()=>s+` Shapes ${e} and ${t} must match`));for(let n=0;n<e.length;n++){const r=e[n],i=t[n];a.Si.assert(r<0||i<0||r===i,(()=>s+` Shapes ${e} and ${t} must match`))}}}function r(e){return"number"!=typeof e&&!e.some((e=>e<0))}function i(e,t,s){let n=o(e,s);const i=!r(n);if(i&&0===t.length)throw Error("Tried to calculate elements of an empty list with non-fully-defined elementShape: "+n);if(i&&t.forEach((e=>{n=o(e.shape,n)})),!r(n))throw Error("Non-fully-defined elementShape: "+n);return n}function o(e,t){if("number"==typeof e)return t;if("number"==typeof t)return e;if(e.length!==t.length)throw Error(`Incompatible ranks during merge: ${e} vs. ${t}`);const s=[];for(let n=0;n<e.length;++n){const r=e[n],i=t[n];if(r>=0&&i>=0&&r!==i)throw Error(`Incompatible shape during merge: ${e} vs. ${t}`);s[n]=r>=0?r:i}return s}s.d(t,"a",(function(){return n})),s.d(t,"b",(function(){return i})),s.d(t,"c",(function(){return o}));var a=s(616)},1765:function(e,t,s){"use strict";var n,r;s.d(t,"a",(function(){return n})),function(e){e[e.DT_INVALID=0]="DT_INVALID",e[e.DT_FLOAT=1]="DT_FLOAT",e[e.DT_DOUBLE=2]="DT_DOUBLE",e[e.DT_INT32=3]="DT_INT32",e[e.DT_UINT8=4]="DT_UINT8",e[e.DT_INT16=5]="DT_INT16",e[e.DT_INT8=6]="DT_INT8",e[e.DT_STRING=7]="DT_STRING",e[e.DT_COMPLEX64=8]="DT_COMPLEX64",e[e.DT_INT64=9]="DT_INT64",e[e.DT_BOOL=10]="DT_BOOL",e[e.DT_QINT8=11]="DT_QINT8",e[e.DT_QUINT8=12]="DT_QUINT8",e[e.DT_QINT32=13]="DT_QINT32",e[e.DT_BFLOAT16=14]="DT_BFLOAT16",e[e.DT_QINT16=15]="DT_QINT16",e[e.DT_QUINT16=16]="DT_QUINT16",e[e.DT_UINT16=17]="DT_UINT16",e[e.DT_COMPLEX128=18]="DT_COMPLEX128",e[e.DT_HALF=19]="DT_HALF",e[e.DT_RESOURCE=20]="DT_RESOURCE",e[e.DT_VARIANT=21]="DT_VARIANT",e[e.DT_UINT32=22]="DT_UINT32",e[e.DT_UINT64=23]="DT_UINT64",e[e.DT_FLOAT_REF=101]="DT_FLOAT_REF",e[e.DT_DOUBLE_REF=102]="DT_DOUBLE_REF",e[e.DT_INT32_REF=103]="DT_INT32_REF",e[e.DT_UINT8_REF=104]="DT_UINT8_REF",e[e.DT_INT16_REF=105]="DT_INT16_REF",e[e.DT_INT8_REF=106]="DT_INT8_REF",e[e.DT_STRING_REF=107]="DT_STRING_REF",e[e.DT_COMPLEX64_REF=108]="DT_COMPLEX64_REF",e[e.DT_INT64_REF=109]="DT_INT64_REF",e[e.DT_BOOL_REF=110]="DT_BOOL_REF",e[e.DT_QINT8_REF=111]="DT_QINT8_REF",e[e.DT_QUINT8_REF=112]="DT_QUINT8_REF",e[e.DT_QINT32_REF=113]="DT_QINT32_REF",e[e.DT_BFLOAT16_REF=114]="DT_BFLOAT16_REF",e[e.DT_QINT16_REF=115]="DT_QINT16_REF",e[e.DT_QUINT16_REF=116]="DT_QUINT16_REF",e[e.DT_UINT16_REF=117]="DT_UINT16_REF",e[e.DT_COMPLEX128_REF=118]="DT_COMPLEX128_REF",e[e.DT_HALF_REF=119]="DT_HALF_REF",e[e.DT_RESOURCE_REF=120]="DT_RESOURCE_REF",e[e.DT_VARIANT_REF=121]="DT_VARIANT_REF",e[e.DT_UINT32_REF=122]="DT_UINT32_REF",e[e.DT_UINT64_REF=123]="DT_UINT64_REF"}(n||(n={})),function(e){let t;!function(e){e[e.LEGACY=0]="LEGACY",e[e.V1=1]="V1",e[e.V2=2]="V2"}(t=e.CheckpointFormatVersion||(e.CheckpointFormatVersion={}))}(r||(r={}))},1790:function(e,t,s){"use strict";var n,r;s.d(t,"a",(function(){return i})),n=s(616),r=s(1208);class i{constructor(e,t,s,r,i,o,a){this.name=e,this.dtype=t,this.maxSize=s,this.elementShape=r,this.identicalElementShapes=i,this.dynamicSize=o,this.clearAfterRead=a,this.tensors=[],this.closed_=!1,this.idTensor=Object(n.Fh)(0),Object(n.Xf)(this.idTensor)}get id(){return this.idTensor.id}get closed(){return this.closed_}clearAndClose(e){this.tensors.forEach((t=>{null!=e&&e.has(t.tensor.id)||t.tensor.dispose()})),this.tensors=[],this.closed_=!0,this.idTensor.dispose()}size(){return this.tensors.length}read(e){if(this.closed_)throw Error(`TensorArray ${this.name} has already been closed.`);if(e<0||e>=this.size())throw Error(`Tried to read from index ${e}, but array size is: ${this.size()}`);const t=this.tensors[e];if(t.cleared)throw Error(`TensorArray ${this.name}: Could not read index ${e} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);return this.clearAfterRead&&(t.cleared=!0),t.read=!0,t.tensor}readMany(e){return e.map((e=>this.read(e)))}write(e,t){if(this.closed_)throw Error(`TensorArray ${this.name} has already been closed.`);if(e<0||!this.dynamicSize&&e>=this.maxSize)throw Error(`Tried to write to index ${e}, but array is not resizeable and size is: ${this.maxSize}`);const s=this.tensors[e]||{};if(t.dtype!==this.dtype)throw Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e},\n          because the value dtype is ${t.dtype}, but TensorArray dtype is ${this.dtype}.`);if(0!==this.size()||null!=this.elementShape&&0!==this.elementShape.length||(this.elementShape=t.shape),Object(r.a)(this.elementShape,t.shape,`TensorArray ${this.name}: Could not write to TensorArray index ${e}.`),s.read)throw Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been read.`);if(s.written)throw Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been written.`);s.tensor=t,Object(n.Xf)(t),s.written=!0,this.tensors[e]=s}writeMany(e,t){if(e.length!==t.length)throw Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${e.length} is not the same as tensors size: ${t.length}.`);e.forEach(((e,s)=>this.write(e,t[s])))}gather(e,t){if(t&&t!==this.dtype)throw Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${t}`);if(e)e=e.slice(0,this.size());else{e=[];for(let t=0;t<this.size();t++)e.push(t)}if(0===e.length)return Object(n.ui)([],[0].concat(this.elementShape));const s=this.readMany(e);return Object(r.a)(this.elementShape,s[0].shape,"TensorArray shape mismatch: "),Object(n.li)(s,0)}concat(e){if(e&&e!==this.dtype)throw Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${e}`);if(0===this.size())return Object(n.ui)([],[0].concat(this.elementShape));const t=[];for(let n=0;n<this.size();n++)t.push(n);const s=this.readMany(t);return Object(r.a)(this.elementShape,s[0].shape,`TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${s[0].shape})`),Object(n.Ce)(s,0)}scatter(e,t){if(t.dtype!==this.dtype)throw Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);if(e.length!==t.shape[0])throw Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${t.shape[0]}`);const s=Math.max(...e);if(!this.dynamicSize&&s>=this.maxSize)throw Error(`Max index must be < array size (${s}  vs. ${this.maxSize})`);this.writeMany(e,Object(n.Pi)(t,0))}split(e,t){if(t.dtype!==this.dtype)throw Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);let s=0;const r=e.map((e=>(s+=e,s)));if(s!==t.shape[0])throw Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${s}, and tensor's shape is: ${t.shape}`);if(!this.dynamicSize&&e.length!==this.maxSize)throw Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${e.length}), and the TensorArray is not marked as dynamically resizeable`);const i=0===s?0:t.size/s,o=[];Object(n.Ei)((()=>{t=Object(n.wh)(t,[1,s,i]);for(let s=0;s<e.length;++s){const a=[0,0===s?0:r[s-1],0],h=[1,e[s],i];o[s]=Object(n.wh)(Object(n.Uh)(t,a,h),this.elementShape)}return o}));const a=[];for(let n=0;n<e.length;n++)a[n]=n;this.writeMany(a,o)}}},1791:function(e,t,s){"use strict";function n(e,t,s){const n=e.dtype;if(e.shape.length<1)throw Error("Tensor must be at least a vector, but saw shape: "+e.shape);if(e.dtype!==s)throw Error(`Invalid data types; op elements ${e.dtype}, but list elements ${s}`);const r=e.shape.slice(1);Object(h.a)(r,t,"TensorList shape mismatch: ");const i=Object(a.Pi)(e);return new c(i,t,n)}function r(e,t,s,n){return new c([],e,t,n)}function i(e,t,s,n){if(t.length!==e.shape[0])throw Error(`Expected len(indices) == tensor.shape[0], but saw: ${t.length} vs. ${e.shape[0]}`);const r=Math.max(...t);if(null!=n&&-1!==n&&r>=n)throw Error(`Max index must be < array size (${r}  vs. ${n})`);const i=new c([],s,e.dtype,n),o=Object(a.Pi)(e,0);return t.forEach(((e,t)=>{i.setItem(e,o[t])})),i}function o(e,t,s){let n=0;const r=t.map((e=>(n+=e,n)));if(n!==e.shape[0])throw Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${n}, and tensor's shape is: ${e.shape}`);const i=e.shape.slice(1),o=Object(h.c)(i,s),u=0===n?0:e.size/n,l=Object(a.Ei)((()=>{const s=[];e=Object(a.wh)(e,[1,n,u]);for(let n=0;n<t.length;++n){const i=[0,0===n?0:r[n-1],0],h=[1,t[n],u];s[n]=Object(a.wh)(Object(a.Uh)(e,i,h),o)}return e.dispose(),s})),p=new c([],s,e.dtype,t.length);for(let a=0;a<l.length;a++)p.setItem(a,l[a]);return p}var a,h;s.d(t,"a",(function(){return n})),s.d(t,"b",(function(){return r})),s.d(t,"c",(function(){return i})),s.d(t,"d",(function(){return o})),a=s(616),h=s(1208);class c{get id(){return this.idTensor.id}constructor(e,t,s,n=-1){this.tensors=e,this.elementShape=t,this.elementDtype=s,null!=e&&e.forEach((e=>{if(s!==e.dtype)throw Error(`Invalid data types; op elements ${s}, but list elements ${e.dtype}`);Object(h.a)(t,e.shape,"TensorList shape mismatch: "),Object(a.Xf)(e)})),this.idTensor=Object(a.Fh)(0),this.maxNumElements=n,Object(a.Xf)(this.idTensor)}copy(){return new c([...this.tensors],this.elementShape,this.elementDtype)}clearAndClose(e){this.tensors.forEach((t=>{null!=e&&e.has(t.id)||t.dispose()})),this.tensors.length=0,this.idTensor.dispose()}size(){return this.tensors.length}stack(e,t,s=-1){if(t!==this.elementDtype)throw Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);if(-1!==s&&this.tensors.length!==s)throw Error(`Operation expected a list with ${s} elements but got a list with ${this.tensors.length} elements.`);Object(h.a)(e,this.elementShape,"TensorList shape mismatch: ");const n=Object(h.b)(this.elementShape,this.tensors,e);return Object(a.Ei)((()=>{const e=this.tensors.map((e=>Object(a.wh)(e,n)));return Object(a.li)(e,0)}))}popBack(e,t){if(t!==this.elementDtype)throw Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);if(0===this.size())throw Error("Trying to pop from an empty list.");const s=Object(h.b)(this.elementShape,this.tensors,e),n=this.tensors.pop();return n.kept=!1,Object(h.a)(n.shape,e,"TensorList shape mismatch: "),Object(a.wh)(n,s)}pushBack(e){if(e.dtype!==this.elementDtype)throw Error(`Invalid data types; op elements ${e.dtype}, but list elements ${this.elementDtype}`);if(Object(h.a)(e.shape,this.elementShape,"TensorList shape mismatch: "),this.maxNumElements===this.size())throw Error("Trying to push element into a full list.");Object(a.Xf)(e),this.tensors.push(e)}resize(e){if(e<0)throw Error("TensorListResize expects size to be non-negative. Got: "+e);if(-1!==this.maxNumElements&&e>this.maxNumElements)throw Error(`TensorListResize input size ${e} is greater maxNumElement ${this.maxNumElements}.`);const t=new c([],this.elementShape,this.elementDtype,this.maxNumElements);t.tensors.length=e;for(let s=0;s<Math.min(this.tensors.length,e);++s)t.tensors[s]=this.tensors[s];return t}getItem(e,t,s){if(s!==this.elementDtype)throw Error(`Invalid data types; op elements ${s}, but list elements ${this.elementDtype}`);if(e<0||e>this.tensors.length)throw Error(`Trying to access element ${e} in a list with ${this.tensors.length} elements.`);if(null==this.tensors[e])throw Error(`element at index ${e} is null.`);Object(h.a)(this.tensors[e].shape,t,"TensorList shape mismatch: ");const n=Object(h.b)(this.elementShape,this.tensors,t);return Object(a.wh)(this.tensors[e],n)}setItem(e,t){if(t.dtype!==this.elementDtype)throw Error(`Invalid data types; op elements ${t.dtype}, but list elements ${this.elementDtype}`);if(e<0||-1!==this.maxNumElements&&e>=this.maxNumElements)throw Error(`Trying to set element ${e} in a list with max ${this.maxNumElements} elements.`);Object(h.a)(this.elementShape,t.shape,"TensorList shape mismatch: "),Object(a.Xf)(t),null!=this.tensors[e]&&(this.tensors[e].kept=!1),this.tensors[e]=t}gather(e,t,s){if(t!==this.elementDtype)throw Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);Object(h.a)(this.elementShape,s,"TensorList shape mismatch: "),e=e.slice(0,this.size());const n=Object(h.b)(this.elementShape,this.tensors,s);return 0===e.length?Object(a.ui)([],[0].concat(n)):Object(a.Ei)((()=>{const t=e.map((e=>Object(a.wh)(this.tensors[e],n)));return Object(a.li)(t,0)}))}concat(e,t){if(e&&e!==this.elementDtype)throw Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${e}`);Object(h.a)(this.elementShape,t,"TensorList shape mismatch: ");const s=Object(h.b)(this.elementShape,this.tensors,t);return 0===this.size()?Object(a.ui)([],[0].concat(s)):Object(a.Ei)((()=>{const e=this.tensors.map((e=>Object(a.wh)(e,s)));return Object(a.Ce)(e,0)}))}}},1798:function(e,t,s){"use strict";var n,r;s.d(t,"a",(function(){return i})),n=s(616),r=s(639);class i{get id(){return this.handle.id}constructor(e,t){this.keyDType=e,this.valueDType=t,this.handle=Object(n.Fh)(0),this.tensorMap=new Map,Object(n.Xf)(this.handle)}clearAndClose(){this.tensorMap.forEach((e=>e.dispose())),this.tensorMap.clear(),this.handle.dispose()}size(){return this.tensorMap.size}tensorSize(){return r.a(this.size(),"int32")}async import(e,t){this.checkKeyAndValueTensor(e,t);const s=await e.data();return this.tensorMap.forEach((e=>e.dispose())),this.tensorMap.clear(),Object(n.Ei)((()=>{const e=Object(n.Pi)(t),r=s.length,i=e.length;n.Si.assert(r===i,(()=>`The number of elements doesn't match, keys has ${r} elements, the values has ${i} elements.`));for(let t=0;t<r;t++){const r=s[t],i=e[t];Object(n.Xf)(i),this.tensorMap.set(r,i)}return this.handle}))}async find(e,t){this.checkKeyAndValueTensor(e,t);const s=await e.data();return Object(n.Ei)((()=>{const e=[];for(let n=0;n<s.length;n++){const r=s[n],i=this.findWithDefault(r,t);e.push(i)}return Object(n.li)(e)}))}findWithDefault(e,t){const s=this.tensorMap.get(e);return null!=s?s:t}checkKeyAndValueTensor(e,t){if(e.dtype!==this.keyDType)throw Error(`Expect key dtype ${this.keyDType}, but got `+e.dtype);if(t.dtype!==this.valueDType)throw Error(`Expect value dtype ${this.valueDType}, but got `+t.dtype)}}},907:function(e,t,s){"use strict";function n(e,t,s,n){const a=new Set,h=[];let c=null,u=null;const l=new Set,d=new Set(Object.keys(e).map((e=>Object(p.g)(e)[0])));n=n||[];const m=new Set(n.map((e=>Object(p.g)(e.name)[0]))),f=[...t];for(;f.length>0;){const e=f.pop();(r(e)||i(e)||o(e))&&null==c&&(c=e,u=c.children.map((e=>e.name)).filter((e=>a.has(e)))),a.add(e.name),null==s[e.name]&&(d.has(e.name)||m.has(e.name)||(0!==e.inputs.length?e.inputs.forEach((e=>{l.has(e.name)||(l.add(e.name),f.push(e))})):h.push(e.name)))}return{inputs:e,outputs:t,usedNodes:a,missingInputs:h,dynamicNode:c,syncInputs:u}}function r(e){return T.has(e.op)}function i(e){return g.has(e.op)}function o(e){return y.has(e.op)}async function a(e,t={},s=u.Sf){if(null==e)throw Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");null==t&&(t={}),t.fromTFHub&&"string"==typeof e&&(e=function(e){return e.endsWith("/")||(e+="/"),`${e}${I}${E}`}(e));const n=new O(e,t,s);return await n.load(),n}function h(e){if(null==e)throw Error("modelUrl in loadGraphModelSync() cannot be null. Please provide model artifacts or an IOHandler that loads the model");let t;if(e instanceof Array){const[s,n]=e;if(!s)throw Error("modelJSON must be the first element of the array");if(!(n&&n instanceof ArrayBuffer))throw Error("An ArrayBuffer of weights must be the second element of the array");if(!("modelTopology"in s))throw Error("Model JSON is missing 'modelTopology'");if(!("weightsManifest"in s))throw Error("Model JSON is missing 'weightsManifest'");const r=u.Sf.getWeightSpecs(s.weightsManifest),i=u.Sf.getModelArtifactsForJSONSync(s,r,n);t=u.Sf.fromMemorySync(i)}else if("load"in e)t=e;else{if(!("modelTopology"in e&&"weightSpecs"in e&&"weightData"in e))throw Error("Unknown model format");t=u.Sf.fromMemorySync(e)}const s=new O(t);return s.load(),s}var c,u=s(616),l=s(1207),p=s(650),d=s(1785);class m{constructor(e={},t={},s={},n={},r){this.weightMap=e,this.tensorArrayMap=t,this.tensorListMap=s,this.functionMap=n,this.parseNodeNameCache=r,this.rootContext={id:0,frameName:"",iterationId:0},this.contexts=[this.rootContext],this.lastId=0,this.generateCurrentContextIds()}newFrame(e,t){return{id:e,frameName:t,iterationId:0}}set currentContext(e){this.contexts!==e&&(this.contexts=e,this.generateCurrentContextIds())}get currentContext(){return this.contexts}get currentContextId(){return this._currentContextIds[0]}get currentContextIds(){return this._currentContextIds}generateCurrentContextIds(){const e=[];for(let t=0;t<this.contexts.length-1;t++){const s=this.contexts.slice(0,this.contexts.length-t);e.push(this.contextIdforContexts(s))}e.push(""),this._currentContextIds=e}contextIdforContexts(e){return e?e.map((e=>0===e.id&&0===e.iterationId?"":`${e.frameName}-${e.iterationId}`)).join("/"):""}enterFrame(e){this.contexts&&(this.lastId++,this.contexts=this.contexts.slice(),this.contexts.push(this.newFrame(this.lastId,e)),this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)))}exitFrame(){if(!(this.contexts&&this.contexts.length>1))throw Error("Cannot exit frame, the context is empty");this.contexts=this.contexts.slice(),this.contexts.splice(-1),this.currentContextIds.shift()}nextIteration(){if(!(this.contexts&&this.contexts.length>0))throw Error("Cannot increase frame iteration, the context is empty");{this.contexts=this.contexts.slice(),this.lastId++;const e=Object.assign({},this.contexts[this.contexts.length-1]);e.iterationId+=1,e.id=this.lastId,this.contexts.splice(-1,1,e),this._currentContextIds.splice(0,1,this.contextIdforContexts(this.contexts))}}getWeight(e){return this.weightMap[e]}addTensorArray(e){this.tensorArrayMap[e.id]=e}getTensorArray(e){return this.tensorArrayMap[e]}addTensorList(e){this.tensorListMap[e.id]=e}getTensorList(e){return this.tensorListMap[e]}dispose(e){for(const t in this.tensorArrayMap)this.tensorArrayMap[t].clearAndClose(e);for(const t in this.tensorListMap)this.tensorListMap[t].clearAndClose(e)}}class f extends Error{constructor(e){super("NodesExecutionOrderError: "+e)}}const T=new Set(["Switch","Merge","Enter","Exit","NextIteration","StatelessIf","StatelessWhile","if","While"]),g=new Set(["NonMaxSuppressionV2","NonMaxSuppressionV3","NonMaxSuppressionV5","Where"]),y=new Set(["HashTable","HashTableV2","LookupTableImport","LookupTableImportV2","LookupTableFind","LookupTableFindV2","LookupTableSize","LookupTableSizeV2"]);class b{get weightIds(){return this.parent?this.parent.weightIds:this._weightIds}get functionExecutorMap(){return this.parent?this.parent.functionExecutorMap:this._functionExecutorMap}get weightMap(){return this.parent?this.parent.weightMap:this._weightMap}set weightMap(e){const t=Object.keys(e).map((t=>e[t].map((e=>e.id))));this._weightIds=[].concat(...t),this._weightMap=e}set resourceManager(e){this._resourceManager=e}get inputs(){return this._inputs.map((e=>({name:e.name,shape:e.attrParams.shape?e.attrParams.shape.value:void 0,dtype:e.attrParams.dtype?e.attrParams.dtype.value:void 0})))}get outputs(){return this._outputs.map((e=>({name:e.name,shape:e.attrParams.shape?e.attrParams.shape.value:void 0,dtype:e.attrParams.dtype?e.attrParams.dtype.value:void 0})))}get inputNodes(){return this._inputs.map((e=>e.signatureKey||e.name))}get outputNodes(){return this._outputs.map((e=>{const t=e.signatureKey||e.name;return e.defaultOutput?`${t}:${e.defaultOutput}`:t}))}get functions(){return Object.keys(this._functions).reduce(((e,t)=>(e[t]=this._functions[t].signature,e)),{})}constructor(e,t){this.graph=e,this.parent=t,this.compiledMap=new Map,this.parseNodeNameCache=new Map,this._weightMap={},this.SEPARATOR=",",this._functions={},this._functionExecutorMap={},this.keepIntermediateTensors=!1,this._outputs=e.outputs,this._inputs=e.inputs,this._initNodes=e.initNodes,this._signature=e.signature,this._functions=e.functions,null!=e.functions&&Object.keys(e.functions).forEach((t=>{this._functionExecutorMap[t]=new b(e.functions[t],this)}))}getCompilationKey(e,t){const s=e.map((e=>e.name)).sort(),n=t.map((e=>e.name)).sort();return s.join(this.SEPARATOR)+"--"+n.join(this.SEPARATOR)}compile(e,t){const s=n(e,t,this.weightMap,this._initNodes),{missingInputs:i,dynamicNode:o,syncInputs:a}=s;if(null!=o)throw Error(`This execution contains the node '${o.name}', which has the dynamic op '${o.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${a}]`);if(i.length>0){const s=t.map((e=>e.name));throw Error(`Cannot compute the outputs [${s}] from the provided inputs [${Object.keys(e)}]. Missing the following inputs: [${i}]`)}const h=function(e,t){function s(e){return[...new Map(e.map((e=>[e.name,e]))).values()]}const{usedNodes:n,inputs:r}=t,i=Object.keys(r).map((e=>Object(p.g)(e)[0])).map((t=>e.nodes[t])),o=e.initNodes||[],a=e=>n.has("string"==typeof e?e:e.name),h=s([...i,...e.weights,...o]).filter(a),c=s([...h,...Object.values(e.nodes)]).filter(a),u=new Map(c.map((e=>[e.name,e]))),l={};for(const p of c){l[p.name]=l[p.name]||0;for(const e of p.children)a(e)||(l[e.name]=1/0),l[e.name]=(l[e.name]||0)+1}const d=Object.entries(l).filter((([,e])=>0===e)).map((([e])=>e)),m=[...d];for(;d.length>0;){const e=d.pop(),t=u.get(e);for(const s of t.children.filter(a))0==--l[s.name]&&(m.push(s.name),d.push(s.name))}const T=function(e,t){const s=new Map(e.map((e=>[e.name,e]))),n=t.map((e=>e.name)),r=new Set(n);for(;n.length>0;){const e=n.pop(),t=s.get(e);for(const i of t.children)s.has(i.name)&&!r.has(i.name)&&(r.add(i.name),n.push(i.name))}return e.filter((e=>r.has(e.name)))}(m.map((e=>u.get(e))),h);return function(e,t){const s=new Map(e.map(((e,t)=>[e.name,t]))),n=new Set(t.map((e=>e.name))),r=e=>n.has("string"==typeof e?e:e.name),i=new Set(e.map((e=>e.name))),o=e=>i.has("string"==typeof e?e:e.name);for(const a of e){for(const e of a.children.filter(o)){if(!s.has(e.name))throw new f(`Child ${e.name} of node ${a.name} is unreachable.`);if(s.get(a.name)>s.get(e.name))throw new f(`Node ${a.name} is scheduled to run after its child ${e.name}.`)}if(!r(a))for(const e of a.inputs){if(!s.has(e.name))throw new f(`Input ${e.name} of node ${a.name} is unreachable.`);if(s.get(e.name)>s.get(a.name))throw new f(`Node ${a.name} is scheduled to run before its input ${e.name}.`)}}}(T,h),T}(this.graph,s),c=function(e){const t=new Map(e.map(((e,t)=>[e.name,t]))),s=Number.MAX_SAFE_INTEGER,n=e.map(((e,t)=>r(e)?s:t)),i=e=>{const s=n[t.get(e.name)];return null==s?-1:s},o=e.map(((e,t)=>e.children.map(i).reduce(((e,t)=>Math.max(e,t)),n[t]))),a=new Map;for(let r=0;r<e.length;++r){const t=o[r];if(t===s)continue;const n=e[r],i=e[t];a.has(i.name)||a.set(i.name,[]),a.get(i.name).push(n)}return a}(h);return{orderedNodes:h,nodeLiveUntilMap:c}}cloneAndKeepTensor(e){if(null==e)return null;const t=e.clone();return Object(u.Xf)(t),t}cloneTensorList(e){return e?e.map((e=>this.cloneAndKeepTensor(e))):null}cloneTensorMap(e){return Object.fromEntries(Object.entries(e).map((([e,t])=>[e,this.cloneTensorList(t)])))}execute(e,t){this.disposeIntermediateTensors(),e=this.mapInputs(e);const s=Object.keys(e).sort();this.checkInputs(e),this.checkInputShapeAndType(e),t=this.mapOutputs(t),this.checkOutputs(t);const n=s.map((e=>this.graph.nodes[Object(p.g)(e)[0]])),r=t.map((e=>Object(p.g)(e)[0])),i=new Set(r);let o=r.map((e=>this.graph.nodes[e]));0===o.length&&(o=this._outputs);const a=this.getCompilationKey(n,o);let h=this.compiledMap.get(a);null==h&&(h=this.compile(e,o),this.compiledMap.set(a,h));try{this.keepIntermediateTensors=Object(u.of)().getBool("KEEP_INTERMEDIATE_TENSORS")}catch(f){this.keepIntermediateTensors=!1,console.warn(f.message)}const c={},l={};return Object(u.Ei)((()=>{const s=new m(this.weightMap,c,l,this.functionExecutorMap,this.parseNodeNameCache),n=Object.assign({},this.weightMap);this.keepIntermediateTensors&&(this.clonedTensorsMap=this.cloneTensorMap(this.weightMap)),Object.keys(e).forEach((t=>{const[r,i]=Object(p.g)(t,s),o=[];o[i]=e[t],n[r]=o,this.keepIntermediateTensors&&(this.clonedTensorsMap[r]=this.cloneTensorList(o))}));const r=this.getFrozenTensorIds(n),{orderedNodes:o,nodeLiveUntilMap:a}=h;for(const e of o){if(n[e.name])continue;const t=Object(d.a)(e,n,s,this._resourceManager);if(u.Si.isPromise(t))throw Error(`The execution of the op '${e.op}' returned a promise. Please use model.executeAsync() instead.`);n[e.name]=t,this.keepIntermediateTensors&&(this.clonedTensorsMap[e.name]=this.cloneTensorList(t)),this.checkTensorForDisposalWithNodeLiveUntilInfo(e,n,s,r,i,a.get(e.name))}return null==this.parent&&s.dispose(r),t.map((e=>Object(p.e)(e,n,s)))}))}getFrozenTensorIds(e){const t=[].concat.apply([],Object.keys(e).map((t=>e[t])).map((e=>e.map((e=>e.id)))));return new Set(t)}checkTensorForDisposal(e,t,s,n,i,o,a){if(!r(t)&&!o.has(e)){for(const n of s[e])null!=n&&(a[n.id]=(a[n.id]||0)+t.children.length);for(const e of t.inputs){if(r(e))continue;const t=Object(p.f)(e.name,s,n);if(null!=t)for(const e of t){if(!e||e.kept||i.has(e.id))continue;const t=a[e.id];1===t?(e.dispose(),delete a[e.id]):null!=t&&a[e.id]--}}}}checkTensorForDisposalWithNodeLiveUntilInfo(e,t,s,n,i,o){function a(e){return r(e)||i.has(e.name)}if(!r(e)&&null!=o)for(const r of o){if(a(r))continue;const e=Object(p.f)(r.name,t,s);for(const t of e)!t||t.kept||n.has(t.id)||t.dispose()}}async executeAsync(e,t){return this._executeAsync(e,t)}disposeIntermediateTensors(){this.clonedTensorsMap&&(Object.values(this.clonedTensorsMap).forEach((e=>{for(const t of e)t&&!t.isDisposed&&t.dispose()})),this.clonedTensorsMap=null)}getIntermediateTensors(){return this.clonedTensorsMap}async _executeAsync(e,t,s=!1,n={},r={}){this.disposeIntermediateTensors(),s||(e=this.mapInputs(e),this.checkInputs(e),this.checkInputShapeAndType(e),t=this.mapOutputs(t),this.checkOutputs(t));try{this.keepIntermediateTensors=Object(u.of)().getBool("KEEP_INTERMEDIATE_TENSORS")}catch(d){this.keepIntermediateTensors=!1,console.warn(d.message)}const i=new m(this.weightMap,n,r,this.functionExecutorMap,this.parseNodeNameCache);this.keepIntermediateTensors&&(this.clonedTensorsMap=this.cloneTensorMap(this.weightMap));const o=await this.executeWithControlFlow(e,i,t,s),a=t.map((e=>Object(p.e)(e,o,i))),h=a.map((e=>e.id)),c=Object.keys(e).map((t=>e[t].id)),l=new Set([...h,...c,...this.weightIds]);return Object.values(o).forEach((e=>{e.forEach((e=>{!e||e.isDisposed||l.has(e.id)||e.dispose()}))})),null==this.parent&&i.dispose(l),a}async executeFunctionAsync(e,t,s){const n=e.reduce(((e,t,s)=>(e[this.inputs[s].name]=t,e)),{});return this._executeAsync(n,this.outputNodes,!0,t,s)}async executeWithControlFlow(e,t,s,i){const o=Object.keys(e),a=o.map((e=>this.graph.nodes[Object(p.g)(e)[0]])),h=s.map((e=>Object(p.g)(e)[0])),c=new Set(h);let u=h.map((e=>this.graph.nodes[e]));0===u.length&&(u=this._outputs);const{usedNodes:l,missingInputs:d,dynamicNode:m,syncInputs:f}=n(e,u,this.weightMap,this._initNodes),T=[...a,...this.graph.weights,...this._initNodes||[]].map((e=>({node:e,contexts:t.currentContext}))),g=Object.assign({},this.weightMap);Object.keys(e).forEach((t=>{const[s,n]=Object(p.g)(t),r=[];r[n]=e[t],g[s]=r}));const y={},b=this.getFrozenTensorIds(g),w={};for(;T.length>0;){const e=this.processStack(a,T,t,g,w,b,c,y,l);await Promise.all(e)}null!=m||i||console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");const E=u.filter((e=>!r(e)&&!Object(p.e)(e.name,g,t))).map((e=>e.name));if(E.length>0){let e="";throw null!=m&&(e=`Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${f}]`),Error(`Cannot compute the outputs [${E}] from the provided inputs [${o}]. Consider providing the following inputs: [${d}]. ${e}`)}return g}processStack(e,t,s,n,r,i,o,a,h){const c=[];for(;t.length>0;){const e=t.pop();s.currentContext=e.contexts;let l="";if("Enter"===e.node.op&&Object(p.d)("isConstant",e.node,n,s)&&([l]=Object(p.b)(e.node.name,s)),null==n[e.node.name]){const m=Object(d.a)(e.node,n,s,this._resourceManager);l||([l]=Object(p.b)(e.node.name,s));const f=s.currentContext;u.Si.isPromise(m)?c.push(m.then((c=>(n[l]=c,this.keepIntermediateTensors&&(this.clonedTensorsMap[l]=this.cloneTensorList(c)),s.currentContext=f,this.checkTensorForDisposal(l,e.node,n,s,i,o,a),this.processChildNodes(e.node,t,s,n,r,h),c)))):(n[l]=m,this.keepIntermediateTensors&&(this.clonedTensorsMap[l]=this.cloneTensorList(m)),this.checkTensorForDisposal(l,e.node,n,s,i,o,a),this.processChildNodes(e.node,t,s,n,r,h))}else this.processChildNodes(e.node,t,s,n,r,h)}return c}processChildNodes(e,t,s,n,r,i){e.children.forEach((e=>{const[o]=Object(p.b)(e.name,s);!r[o]&&i.has(e.name)&&("Merge"===e.op?e.inputNames.some((e=>!!Object(p.e)(e,n,s)))&&(r[o]=!0,t.push({contexts:s.currentContext,node:e})):e.inputNames.every((e=>!!Object(p.e)(e,n,s)))&&(r[o]=!0,t.push({contexts:s.currentContext,node:e})))}))}dispose(){Object.keys(this.weightMap).forEach((e=>this.weightMap[e].forEach((e=>e.dispose()))))}checkInputShapeAndType(e){Object.keys(e).forEach((t=>{const s=e[t],[n]=Object(p.g)(t),r=this.graph.nodes[n];if(r.attrParams.shape&&r.attrParams.shape.value){const e=r.attrParams.shape.value,t=e.length===s.shape.length&&s.shape.every(((t,s)=>-1===e[s]||e[s]===t));u.Si.assert(t,(()=>`The shape of dict['${r.name}'] provided in model.execute(dict) must be [${e}], but was [${s.shape}]`))}r.attrParams.dtype&&r.attrParams.dtype.value&&u.Si.assert(s.dtype===r.attrParams.dtype.value,(()=>`The dtype of dict['${r.name}'] provided in model.execute(dict) must be ${r.attrParams.dtype.value}, but was ${s.dtype}`))}))}mapInputs(e){var t,s;const n={};for(const r in e){const i=null===(s=null===(t=this._signature)||void 0===t?void 0:t.inputs)||void 0===s?void 0:s[r];null!=i?n[i.name]=e[r]:n[r]=e[r]}return n}checkInputs(e){const t=Object.keys(e).filter((e=>{const[t]=Object(p.g)(e);return null==this.graph.nodes[t]}));if(t.length>0)throw Error(`The dict provided in model.execute(dict) has keys: [${t}] that are not part of graph`)}mapOutputs(e){return e.map((e=>{var t,s;const n=null===(s=null===(t=this._signature)||void 0===t?void 0:t.outputs)||void 0===s?void 0:s[e];return null!=n?n.name:e}),{})}checkOutputs(e){e.forEach((e=>{const[t]=Object(p.g)(e);if(!this.graph.nodes[t])throw Error(`The output '${e}' is not found in the graph`)}))}}class w{constructor(e={},t={}){this.hashTableNameToHandle=e,this.hashTableMap=t}addHashTable(e,t){this.hashTableNameToHandle[e]=t.handle,this.hashTableMap[t.id]=t}getHashTableHandleByName(e){return this.hashTableNameToHandle[e]}getHashTableById(e){return this.hashTableMap[e]}dispose(){for(const e in this.hashTableMap)this.hashTableMap[e].clearAndClose(),delete this.hashTableMap[e];for(const e in this.hashTableNameToHandle)this.hashTableNameToHandle[e].dispose(),delete this.hashTableNameToHandle[e]}}c=s(672),s.d(t,"a",(function(){return O})),s.d(t,"b",(function(){return a})),s.d(t,"c",(function(){return h}));const E="?tfjs-format=file",I="model.json";class O{get modelVersion(){return this.version}get inputNodes(){return this.executor.inputNodes}get outputNodes(){return this.executor.outputNodes}get inputs(){return this.executor.inputs}get outputs(){return this.executor.outputs}get weights(){return this.executor.weightMap}get metadata(){return this.artifacts.userDefinedMetadata}get modelSignature(){return this.signature}get modelStructuredOutputKeys(){return this.structuredOutputKeys}constructor(e,t={},s=u.Sf){this.modelUrl=e,this.loadOptions=t,this.version="n/a",this.io=s,null==t&&(this.loadOptions={}),this.resourceManager=new w}findIOHandler(){const e=this.modelUrl;if(null!=e.load)this.handler=e;else if(null!=this.loadOptions.requestInit)this.handler=this.io.browserHTTPRequest(e,this.loadOptions);else{const t=this.io.getLoadHandlers(e,this.loadOptions);if(0===t.length)t.push(this.io.browserHTTPRequest(e,this.loadOptions));else if(t.length>1)throw Error(`Found more than one (${t.length}) load handlers for URL '${[e]}'`);this.handler=t[0]}}load(){if(this.findIOHandler(),null==this.handler.load)throw Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const e=this.handler.load();return u.Si.isPromise(e)?e.then((e=>null==e.getWeightStream?this.loadSync(e):this.loadStreaming(e))):this.loadSync(e)}loadSync(e){const t=this.io.decodeWeights(e.weightData,e.weightSpecs);return this.loadWithWeightMap(e,t)}async loadStreaming(e){if(null==e.getWeightStream)throw Error("Model artifacts missing streamWeights function");const t=await Object(c.f)(e.getWeightStream(),e.weightSpecs);return this.loadWithWeightMap(e,t)}loadWithWeightMap(e,t){this.artifacts=e;const s=this.artifacts.modelTopology;let n=this.artifacts.signature;if(null!=this.artifacts.userDefinedMetadata){const e=this.artifacts.userDefinedMetadata;null!=e.signature&&(n=e.signature),null!=e.structuredOutputKeys&&(this.structuredOutputKeys=e.structuredOutputKeys)}if(this.signature=n,this.version=`${s.versions.producer}.${s.versions.minConsumer}`,this.executor=new b(l.a.Instance.transformGraph(s,this.signature)),this.executor.weightMap=this.convertTensorMapToTensorsMap(t),this.executor.resourceManager=this.resourceManager,null!=e.modelInitializer&&null!=e.modelInitializer.node){const t=l.a.Instance.transformGraph(e.modelInitializer);this.initializer=new b(t),this.initializer.weightMap=this.executor.weightMap,this.initializer.resourceManager=this.resourceManager,this.initializerSignature=e.initializerSignature}return!0}async save(e,t){if("string"==typeof e){const t=this.io.getSaveHandlers(e);if(0===t.length)throw Error(`Cannot find any save handlers for URL '${e}'`);if(t.length>1)throw Error(`Found more than one (${t.length}) save handlers for URL '${e}'`);e=t[0]}if(null==e.save)throw Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");return e.save(this.artifacts)}addStructuredOutputNames(e){if(this.structuredOutputKeys){const t=e instanceof u.Dd?[e]:e,s={};return t.forEach(((e,t)=>s[this.structuredOutputKeys[t]]=e)),s}return e}predict(e,t){const s=this.execute(e,this.outputNodes);return this.addStructuredOutputNames(s)}async predictAsync(e,t){const s=await this.executeAsync(e,this.outputNodes);return this.addStructuredOutputNames(s)}normalizeInputs(e){var t;if(!(e instanceof u.Dd||Array.isArray(e))){const s=null===(t=this.signature)||void 0===t?void 0:t.inputs;if(null!=s)for(const t in s){const n=s[t];null!=n.resourceId&&(e[t]=this.resourceIdToCapturedInput[n.resourceId])}return e}e=Array.isArray(e)?e:[e];const s=Object.keys(this.resourceIdToCapturedInput).length;if(e.length+s!==this.inputNodes.length)throw Error(`Input tensor count mismatch, the graph model has ${this.inputNodes.length-s} non-resource placeholders, while there are ${e.length} input tensors provided.`);let n=0;return this.inputNodes.reduce(((t,s)=>{var r,i,o;const a=null===(o=null===(i=null===(r=this.signature)||void 0===r?void 0:r.inputs)||void 0===i?void 0:i[s])||void 0===o?void 0:o.resourceId;return t[s]=null!=a?this.resourceIdToCapturedInput[a]:e[n++],t}),{})}normalizeOutputs(e){return e=e||this.outputNodes,Array.isArray(e)?e:[e]}executeInitializerGraph(){return null==this.initializer?[]:null==this.initializerSignature?this.initializer.execute({},[]):this.initializer.execute({},Object.keys(this.initializerSignature.outputs))}async executeInitializerGraphAsync(){return null==this.initializer?[]:null==this.initializerSignature?this.initializer.executeAsync({},[]):this.initializer.executeAsync({},Object.keys(this.initializerSignature.outputs))}setResourceIdToCapturedInput(e){if(this.resourceIdToCapturedInput={},this.initializerSignature){const t=this.initializerSignature.outputs,s=Object.keys(t);for(let n=0;n<s.length;n++){const r=t[s[n]];this.resourceIdToCapturedInput[r.resourceId]=e[n]}}}execute(e,t){null==this.resourceIdToCapturedInput&&this.setResourceIdToCapturedInput(this.executeInitializerGraph()),e=this.normalizeInputs(e),t=this.normalizeOutputs(t);const s=this.executor.execute(e,t);return s.length>1?s:s[0]}async executeAsync(e,t){null==this.resourceIdToCapturedInput&&this.setResourceIdToCapturedInput(await this.executeInitializerGraphAsync()),e=this.normalizeInputs(e),t=this.normalizeOutputs(t);const s=await this.executor.executeAsync(e,t);return s.length>1?s:s[0]}getIntermediateTensors(){return this.executor.getIntermediateTensors()}disposeIntermediateTensors(){this.executor.disposeIntermediateTensors()}convertTensorMapToTensorsMap(e){return Object.keys(e).reduce(((t,s)=>(t[s]=[e[s]],t)),{})}dispose(){this.executor.dispose(),this.initializer&&(this.initializer.dispose(),this.resourceIdToCapturedInput&&Object(u.bf)(this.resourceIdToCapturedInput)),this.resourceManager.dispose()}}}}]);